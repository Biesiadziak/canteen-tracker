import requests
from bs4 import BeautifulSoup
from datetime import datetime
import time
from services import translate_text, extract_dishes_ai
from models import save_menu
import re
from facebook_scraper import get_posts

# Note: Scraping Facebook directly is difficult due to dynamic content and login walls.
# This is a simplified scraper that attempts to get public page content.
# For a production app, you would likely need the Facebook Graph API or a library like 'facebook-scraper' with cookies.

FB_PAGE_ID = "stolowkaPP"

def check_for_new_menu(force=False):
    print(f"Checking for new menu (force={force})...")
    
    today = datetime.now().strftime("%Y-%m-%d")
    
    # SKIP FACEBOOK SCRAPING - IT IS UNRELIABLE WITHOUT COOKIES
    # Using the fallback text provided by the user directly.
    print("Using fallback/mock data directly (Scraping disabled).")
    scraped_text_pl = """
CZ
ğŸ¥’ Czasem to wÅ‚aÅ›nie warzywo w roli gÅ‚Ã³wnej potrafi najlepiej "zrobiÄ‡" dzieÅ„, rozluÅºniÄ‡ myÅ›li i sprawiÄ‡, Å¼e wszystko â€“ choÄ‡by na chwilÄ™ â€“ wskakuje na swoje miejsce.
DziÅ› serwujemy faszerowanÄ… cukiniÄ™.
MiÄ™kkÄ…, pieczonÄ…, z nadzieniem tak treÅ›ciwym, Å¼e nawet najwiÄ™ksi fani karkÃ³wki przyznajÄ…:
ğŸ‘‰ â€No dobra, to ma sens.â€
Bo dobry comfort food nie musi kapaÄ‡ tÅ‚uszczem i spoczywaÄ‡ na gÃ³rze ziemniakÃ³w.
Czasem to po prostu dobrze przyprawione, ciepÅ‚e, miÄ™kkie w Å›rodku i chrupiÄ…ce z wierzchu warzywo.
ğŸŒ¿ A jeÅ›li szukasz czegoÅ› innego â€“ teÅ¼ nie bÄ™dziesz zawiedziony:
ğŸ¥© PolÄ™dwiczki wieprzowe w sosie grzybowym
ğŸ– Golonka pieczona â€“ klasyk dla odwaÅ¼nych
ğŸ“ Å»oÅ‚Ä…dki drobiowe w sosie koperkowym
ğŸ— Noga z kurczaka 
ğŸ¥£ Zupa? Krem ziemniaczany z imbirem i gruszkÄ… â€“ nasz rozgrzewajÄ…cy znak firmowy ğŸ”¥
ğŸ¥— Dodatki: ziemniaki, ryÅ¼ z warzywami, warzywo na ciepÅ‚o, surÃ³wki
    """

    # 1. Translate
    print("Translating...")
    translated_text = translate_text(scraped_text_pl)
    
    # 2. Extract Dishes (AI Only)
    print("Extracting dishes...")
    
    dishes = extract_dishes_ai(scraped_text_pl)
    
    if not dishes:
        print("AI extraction failed. Returning empty list.")
        dishes = []
    
    # dishes is now a list of objects: [{"pl": "...", "en": "..."}]
    # We store this directly as the "images" data structure for now
    images_data = dishes
            
    # 3. Save
    is_new = save_menu(today, scraped_text_pl, translated_text, images_data, force_update=force)
    
    if is_new:
        print(f"New menu saved for {today}")
        return True
    else:
        print("Menu for today already exists.")
        return False

# Real implementation note:
# To scrape FB properly, you might use:
# from facebook_scraper import get_posts
# for post in get_posts('stolowkaPP', pages=1):
#     text = post['text']
#     ... process text ...
